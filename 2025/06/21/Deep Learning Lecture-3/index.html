<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Deep Learning Lecture-3 | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="Convolutional Neural Networks卷积网络最早是用来处理图像的问题。目前较为成功的研究是物体识别问题，对于物体之间的关系推断依然是计算机视觉的前沿领域。 在生物的研究中，存在感受野receptive field的概念，这是指神经元对于输入的局部区域的敏感程度。在卷积网络中，我们也引入了这个概念。相邻的神经元处理的是相邻的图像区域，这样的设计使得网络能够捕捉到图像的空间结构">
<meta property="og:type" content="article">
<meta property="og:title" content="Deep Learning Lecture-3">
<meta property="og:url" content="http://example.com/2025/06/21/Deep%20Learning%20Lecture-3/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="Convolutional Neural Networks卷积网络最早是用来处理图像的问题。目前较为成功的研究是物体识别问题，对于物体之间的关系推断依然是计算机视觉的前沿领域。 在生物的研究中，存在感受野receptive field的概念，这是指神经元对于输入的局部区域的敏感程度。在卷积网络中，我们也引入了这个概念。相邻的神经元处理的是相邻的图像区域，这样的设计使得网络能够捕捉到图像的空间结构">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="d:/software/Git/images/%7B71895E3A-0EFA-438D-8E6C-EDBD4A337F5A%7D.png">
<meta property="og:image" content="d:/software/Git/images/%7B7AC9125F-FA2D-42F9-B0CF-085ABFFB668F%7D.png">
<meta property="og:image" content="d:/software/Git/images/%7B7202EECA-CD25-4EE1-A5C9-02F0263C968C%7D.png">
<meta property="og:image" content="d:/software/Git/images/%7BCFAAFBDA-A81C-4931-9C2C-CBD64F40E29C%7D.png">
<meta property="og:image" content="d:/software/Git/images/%7B01688551-C69C-4B62-8660-637A51409678%7D.png">
<meta property="og:image" content="d:/software/Git/images/%7B1197B7EA-3F5B-40C9-8ADF-861B8AACBDC2%7D.png">
<meta property="og:image" content="d:/software/Git/images/%7B382F2347-B42F-46CB-83DB-F25DDE49A91E%7D.png">
<meta property="og:image" content="d:/software/Git/images/%7B43BF44F4-D211-4165-AE84-257E702582A0%7D.png">
<meta property="og:image" content="d:/software/Git/images/%7B6F8AFF72-4C3D-4FAD-8FC9-90F7FED6E8B2%7D.png">
<meta property="og:image" content="d:/software/Git/images/%7B39D210C3-7C1B-4913-AC78-12E71A8FD13B%7D.png">
<meta property="og:image" content="d:/software/Git/images/%7BE3B121C1-5782-4762-A983-042799DA4ED9%7D.png">
<meta property="og:image" content="d:/software/Git/images/%7B6767A6D4-59B6-4B62-9FE9-427D009BB837%7D.png">
<meta property="og:image" content="d:/software/Git/images/%7B8F67BE27-E8CA-4921-99B2-C57FFFAE5E7B%7D.png">
<meta property="og:image" content="d:/software/Git/images/%7B681C5361-F2ED-427F-86C2-48C9EC68AADF%7D.png">
<meta property="og:image" content="d:/software/Git/images/%7B5DE8620F-D5FB-4E82-96D7-0E03CCCCAF82%7D.png">
<meta property="og:image" content="d:/software/Git/images/Pasted%20image%2020250316132626.png">
<meta property="og:image" content="d:/software/Git/images/Pasted%20image%2020250316134751.png">
<meta property="article:published_time" content="2025-06-20T16:00:00.000Z">
<meta property="article:modified_time" content="2025-06-24T07:00:41.713Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="DeepLearning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="d:/software/Git/images/%7B71895E3A-0EFA-438D-8E6C-EDBD4A337F5A%7D.png">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/fork-awesome@1.2.0/css/fork-awesome.min.css">





<script>
  MathJax = {
    tex: {
      // vvvvv  请务必确认存在这一行 vvvvv
      packages: {'[+]': ['ams']},
      // ^^^^^  请务必确认存在这一行 ^^^^^
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$', '$$'], ['\\[', '\\]']],
      processEscapes: true,
      processEnvironments: true
    },
    options: {
      skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
    }
  };
</script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<meta name="generator" content="Hexo 7.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-Deep Learning Lecture-3" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/06/21/Deep%20Learning%20Lecture-3/" class="article-date">
  <time class="dt-published" datetime="2025-06-20T16:00:00.000Z" itemprop="datePublished">2025-06-21</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      Deep Learning Lecture-3
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <hr>
<h2 id="Convolutional-Neural-Networks"><a href="#Convolutional-Neural-Networks" class="headerlink" title="Convolutional Neural Networks"></a>Convolutional Neural Networks</h2><p>卷积网络最早是用来处理图像的问题。目前较为成功的研究是物体识别问题，对于物体之间的关系推断依然是计算机视觉的前沿领域。</p>
<p>在生物的研究中，存在<strong>感受野</strong><em>receptive field</em>的概念，这是指神经元对于输入的局部区域的敏感程度。在卷积网络中，我们也引入了这个概念。相邻的神经元处理的是相邻的图像区域，这样的设计使得网络能够捕捉到图像的空间结构。在模拟人类的视觉系统中，重要的是<strong>提取不同程度的特征</strong>，这就是卷积网络的核心思想。</p>
<p>在MLP中，由于对于原图像像素进行展开，会损失部分的空间信息。在处理视角、光照的变化时，MLP的效果会变差。</p>
<p><img src="D:/software/Git/images/%7B71895E3A-0EFA-438D-8E6C-EDBD4A337F5A%7D.png" alt="{71895E3A-0EFA-438D-8E6C-EDBD4A337F5A}.png"></p>
<p>从左到右，逐步提取的是从较低到较高的层次特征。在不同的任务中使用不同的特征。在识别人物中，应该使用较高层次的特征。</p>
<h5 id="Local-Connectivity"><a href="#Local-Connectivity" class="headerlink" title="Local Connectivity"></a>Local Connectivity</h5><p>每一层的神经元只连接到上一层的局部区域。具体的连接方式为：每一个神经元只关注上一层对应区域的部分神经元。</p>
<h5 id="Parameter-Sharing"><a href="#Parameter-Sharing" class="headerlink" title="Parameter Sharing"></a>Parameter Sharing</h5><p>一个神经元对应的某组参数代表的是某种特征，我们认为提取的特征的在不同的位置是一样的。是一种<strong>平移不变性</strong>。</p>
<h4 id="Convolution"><a href="#Convolution" class="headerlink" title="Convolution"></a>Convolution</h4><p>$f$是输入的图像，$g$是卷积核，卷积操作定义为：<br><em>Continuous function</em> :<br>$$<br>(f*g)(t) &#x3D; \int_{-\infty}^{\infty} f(\tau)g(t-\tau)d\tau<br>$$<br><em>Discrete function</em> :<br>$$<br>(f*g)[n] &#x3D; \sum_{m&#x3D;-\infty}^{\infty} f[m]g[n-m]<br>$$<br>上述操作的目的为对于输入函数</p>
<h5 id="Cross-Correlation"><a href="#Cross-Correlation" class="headerlink" title="Cross Correlation"></a>Cross Correlation</h5><p>互相关用来分析两个信号的相似性，定义为：<br><em>Continous function</em> :<br>$$<br>(f\star g)(t) &#x3D; \int_{-\infty}^{\infty} \overline {f(\tau)}g(t+\tau)d\tau<br>$$<br><em>Discrete function</em> :<br>$$<br>(f\star g)[n] &#x3D; \sum_{m&#x3D;-\infty}^{\infty} \overline {f[m]}g[n+m]<br>$$<br>对于卷积和互相关的关系为：<br>$$<br>[f(t) \star g(t)] (t) &#x3D; [\overline{f(-t)} * g(t)](t)<br>$$<br>事实上，在卷积网络中使用的是互相关操作。</p>
<h5 id="Notation"><a href="#Notation" class="headerlink" title="Notation"></a>Notation</h5><ul>
<li>输入的图片一般为三层，分别为RGB。这个<em>Volume</em>是一个张量<em>Tensor</em>。</li>
<li>卷积核的大小为$5 \times 5 \times 3$（举例），即3个通道，每个通道大小为$5 \times 5$。然后在整个图片上进行平移，计算卷积操作。（类似于卷积的定义）</li>
<li>卷积的计算操作为：卷积核在图片上平移，计算对应位置的乘积和。<br><img src="D:/software/Git/images/%7B7AC9125F-FA2D-42F9-B0CF-085ABFFB668F%7D.png" alt="{7AC9125F-FA2D-42F9-B0CF-085ABFFB668F}.png"><br>上面的公式是在移动到某个位置$(w,h)$的时候，计算对应位置的乘积和。然后将结果存储在一个新的矩阵中。</li>
</ul>
<p><em>在实际操作的过程中，并不要将卷积核在图片上“滑动”（这是一个串行算法），可以为每一个为每一个局域来分配一个神经元，这样的操作是并行的，可以加速计算。</em></p>
<p>得到的是一个Feature Map，这个Feature Map是一个新的张量，使用6个卷积核得到的图片的特征图的大小为$28 \times 28 \times 6$。<em>如何计算的？参数量是多少？</em><br>使用的卷积核数量是一个超参数，可以调整。</p>
<p>对于一个$w*h*c$的输入，使用$k*k*c*d$个卷积核，得到的输出的特征图的大小为$(w-k+1)*(h-k+1)*d$，参数量为$(k*k*c+1)*d$。但是CNN在实践过程中的显存占用是较大的，因为需要存储特征图。</p>
<p><img src="D:/software/Git/images/%7B7202EECA-CD25-4EE1-A5C9-02F0263C968C%7D.png" alt="{7202EECA-CD25-4EE1-A5C9-02F0263C968C}.png"></p>
<h4 id="Dilated-Stride-Convolution"><a href="#Dilated-Stride-Convolution" class="headerlink" title="Dilated&amp; Stride Convolution"></a>Dilated&amp; Stride Convolution</h4><p>在卷积操作中，我们可以使用不同的步长来进行卷积操作，这样的操作会改变输出的大小。在Dilated Convolution中，我们可以使用不同的扩张率来进行卷积操作。扩张率为1的时候<em>1-dilated</em>是正常的卷积操作，扩张率为2的时候，卷积核的间隔为2 <em>2-dilated</em>。这样的操作可以<strong>增加卷积核的感受野</strong>，但是减少了输出的大小。</p>
<p><em>Stride</em>是卷积核的步长，可以让输出的特征图迅速变小。<br>可能出现不匹配的情况，这样可以进行<em>Padding</em>是在边缘填充0，这样的操作可以保持输出的大小。</p>
<h5 id="Activation-Functions"><a href="#Activation-Functions" class="headerlink" title="Activation Functions"></a>Activation Functions</h5><p>在卷积网络中，激活函数可以使用ReLU函数，这样的操作可以避免梯度消失的问题。有时候使用的是Leaky ReLU函数，这样的操作在某些模型中可以减少神经元死亡的问题。<br>$$<br>LeakyReLU(x) &#x3D; \begin{cases} x &amp; x&gt;0 \\ 0.01x &amp; x \leq 0 \end{cases}<br>$$</p>
<p><img src="D:/software/Git/images/%7BCFAAFBDA-A81C-4931-9C2C-CBD64F40E29C%7D.png" alt="{CFAAFBDA-A81C-4931-9C2C-CBD64F40E29C}.png"></p>
<h5 id="Pooling"><a href="#Pooling" class="headerlink" title="Pooling"></a>Pooling</h5><p>池化操作一般是用来减少空间尺寸，这样的操作可以减少参数量，减少过拟合的问题。</p>
<ul>
<li>Max Pooling：取局部区域的最大值</li>
<li>Average Pooling：取局部区域的平均值<br><img src="D:/software/Git/images/%7B01688551-C69C-4B62-8660-637A51409678%7D.png" alt="{01688551-C69C-4B62-8660-637A51409678}.png"></li>
</ul>
<p><strong>Spatial Pyramid Pooling</strong>：对于不同的通道进行池化操作，这样的操作可以增加特征的多样性。这是用来减少多尺度问题的。<br>在现实生活中，多尺度是一个基本的特征，例如在大气系统、气候系统中，有较大的气流和较小部分的湍流。</p>
<h3 id="Back-Propagation"><a href="#Back-Propagation" class="headerlink" title="Back Propagation"></a>Back Propagation</h3><p><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=Ilg3gGewQ5U">Backpropagation, step-by-step | DL3</a></p>
<p><img src="D:/software/Git/images/%7B1197B7EA-3F5B-40C9-8ADF-861B8AACBDC2%7D.png" alt="{1197B7EA-3F5B-40C9-8ADF-861B8AACBDC2}.png"></p>
<p>在卷积网络的前向传播中每一层的计算公式如下：<br>$$<br>z_d^{(l+1)} &#x3D; a^{(l)}\star \theta^{(l)}_d + b^{(l)}_d<br>$$</p>
<p>在一个具体的例子中，可以计算一个$3 \times 3 \times 1$的图像在经过一个$2\times 2 \times 1$的卷积核得到的$2 \times 2 \times 1$的特征图的计算过程。</p>
<ul>
<li>Consider single input channel $c&#x3D;1$ :<br>$$<br>\left[\begin{array}{ll}<br>z_{11}^{(l+1)} &amp; z_{12}^{(l+1)} \\<br>z_{21}^{(l+1)} &amp; z_{22}^{(l+1)}<br>\end{array}\right]&#x3D;\left[\begin{array}{lll}<br>a_{11}^{(l)} &amp; a_{12}^{(l)} &amp; a_{13}^{(l)} \\<br>a_{21}^{(l)} &amp; a_{22}^{(l)} &amp; a_{23}^{(l)} \\<br>a_{31}^{(l)} &amp; a_{32}^{(l)} &amp; a_{33}^{(l)}<br>\end{array}\right] \star\left[\begin{array}{ll}<br>\theta_{11}^{(l)} &amp; \theta_{12}^{(l)} \\<br>\theta_{21}^{(l)} &amp; \theta_{22}^{(l)}<br>\end{array}\right]<br>$$</li>
<li>Expand above to be clearer:<br>$$<br>\left\{\begin{array}{l}<br>z_{11}^{(l+1)}&#x3D;a_{11}^{(l)} \theta_{11}^{(l)}+a_{12}^{(l)} \theta_{12}^{(l)}+a_{21}^{(l)} \theta_{21}^{(l)}+a_{22}^{(l)} \theta_{22}^{(l)} \\<br>z_{12}^{(l+1)}&#x3D;a_{12}^{(l)} \theta_{11}^{(l)}+a_{13}^{(l)} \theta_{12}^{(l)}+a_{22}^{(l)} \theta_{21}^{(l)}+a_{23}^{(l)} \theta_{22}^{(l)} \\<br>z_{21}^{(l+1)}&#x3D;a_{21}^{(l)} \theta_{11}^{(l)}+a_{22}^{(l)} \theta_{12}^{(l)}+a_{31}^{(l)} \theta_{21}^{(l)}+a_{32}^{(l)} \theta_{22}^{(l)} \\<br>z_{22}^{(l+1)}&#x3D;a_{22}^{(l)} \theta_{11}^{(l)}+a_{23}^{(l)} \theta_{12}^{(l)}+a_{32}^{(l)} \theta_{21}^{(l)}+a_{33}^{(l)} \theta_{22}^{(l)}<br>\end{array}\right.<br>$$</li>
</ul>
<p>对于上述的例子计算残差网络的过程为：<br>$$<br>\begin{aligned}<br>\delta_{ij}^{(l)} &amp; &#x3D; \frac{\partial J(\theta,b)}{\partial z_{ij}^{(l)}}  &#x3D;  \frac{\partial J(\theta,b)}{\partial a_{ij}^{(l)}} \frac{\partial a_{ij}^{(l)}}{\partial z^{(l)}_{ij}}\\<br>&amp;&#x3D; \sum_{z_{pq}^{(l+1)} \in  Pa(a_{ij}^{(l)})} \frac{\partial J(\theta,b)}{\partial z_{pq}^{(l+1)}} \frac{\partial z_{pq}^{(l+1)}}{\partial a_{ij}^{(l)}} \frac{\partial a_{ij}^{(l)}}{\partial z^{(l)}_{ij}} \\<br>&amp;&#x3D; \sum_{z_{pq}^{(l+1)} \in Pa(a_{ij}^{(l)}) } \delta_{pq}^{(l+1)} \frac{\partial z_{pq}^{(l+1)}}{\partial a_{ij}^{(l)}} g&#39;(z_{ij}^{(l)})<br>\end{aligned}<br>$$</p>
<p>与全连接层的计算公式的不同在于，CNN是一个局部的计算过程，即每一个神经元的输出值并不会对后一层的所有神经元产生影响。</p>
<p>对于上述计算得到的残差，可以写成一个矩阵：<br>$$<br>\delta^{(l)} &#x3D; \left[\begin{array}{lll}<br>\delta_{11}^{(l)} &amp; \cdots &amp; \delta_{1n}^{(l)} \\<br>\vdots &amp; \ddots &amp; \vdots \\<br>\delta_{m1}^{(l)} &amp; \cdots &amp; \delta_{mn}^{(l)}<br>\end{array}\right]<br>$$<br>在上面的例子中，我们可以计算得到：<br>$$<br>\left[\begin{array}{lll}<br>\delta_{11}^{(l)} &amp; \delta_{12}^{(l)} &amp; \delta_{13}^{(l)} \\<br>\delta_{21}^{(l)} &amp; \delta_{22}^{(l)} &amp; \delta_{23}^{(l)} \\<br>\delta_{31}^{(l)} &amp; \delta_{32}^{(l)} &amp; \delta_{33}^{(l)}<br>\end{array}\right]&#x3D;\left[\begin{array}{cccc}<br>0 &amp; 0 &amp; 0 &amp; 0 \\<br>0 &amp; \delta_{11}^{(l+1)} &amp; \delta_{12}^{(l+1)} &amp; 0 \\<br>0 &amp; \delta_{21}^{(l+1)} &amp; \delta_{22}^{(l+1)} &amp; 0 \\<br>0 &amp; 0 &amp; 0 &amp; 0<br>\end{array}\right] \star\left[\begin{array}{cc}<br>\theta_{22}^{(l)} &amp; \theta_{21}^{(l)} \\<br>\theta_{12}^{(l)} &amp; \theta_{11}^{(l)}<br>\end{array}\right] \odot g^{\prime}\left(z^{(l)}\right)<br>$$<br>比较紧凑地写出：<br>$$<br>\delta^{(l)} &#x3D; \delta^{(l+1)} \star rot180(\theta^{(l)}) \odot g^{\prime}(z^{(l)})<br>$$<br>其中$rot180$是对卷积核进行旋转180度的操作。<br>$\odot$对应的是两个矩阵的逐个元素乘</p>
<p>在有多张特征图的情况下（输出有$d$个通道），输入的图像有$c$通道，我们可以将上述的计算过程进行扩展，得到：<br>$$<br>\delta^{(l)} &#x3D; \sum_{d} \delta^{(l+1)}_d \star rot180(\theta^{(l)}) \odot g^{\prime}(z^{(l)})<br>$$<br>在计算目标函数对于参数的导数的过程中，我们可以得到：<br>$$<br>\frac{\partial J(\theta,b)}{\partial \theta_d^{(l)}} &#x3D; \frac{\partial J(\theta,b)}{\partial z_d^{(l+1)}} \frac{\partial z_d^{(l+1)}}{\partial \theta_d^{(l)}}<br>&#x3D; \delta_d^{(l+1)} \star a^{(l)}_d<br>$$<br>可以更加详细地计算：<br>$$<br>\begin{aligned}<br>\frac{\partial J(\theta,b)}{\partial \theta_{i,j,k,d}^{(l)}} &amp;&#x3D;<br>\sum_{m,n} \frac{\partial J(\theta,b)}{\partial z_{m,n}^{(l+1)}} \frac{\partial z_{m,n}^{(l+1)}}{\partial \theta_{i,j,k,d}^{(l)}} \\<br>&amp;&#x3D; \sum_{m,n} \delta_{m,n}^{(l+1)} a_{m+i-1,n+j-1,k}^{(l)} \\<br>&amp;&#x3D; \delta_d^{(l+1)} \star a^{(l)}_d<br>\end{aligned}<br>$$<br>对于偏置项的计算过程为<br>$$<br>\frac{\partial J(\theta,b) }{\partial b_d^{(l)}} &#x3D; \sum_{m,n} \frac{\partial J(\theta,b)}{\partial z_{m,n}^{(l+1)}} \frac{\partial z_{m,n}^{(l+1)}}{\partial b_d^{(l)}} &#x3D; \sum_{m,n} \delta_{m,n}^{(l+1)}<br>$$</p>
<p>从而可以使用<strong>动量的梯度</strong>下降的方法来进行参数的更新。</p>
<h3 id="Invariance-and-Equivariance"><a href="#Invariance-and-Equivariance" class="headerlink" title="Invariance and Equivariance"></a>Invariance and Equivariance</h3><p>对于不同的任务，有时候需要不变性和等变性。在图像处理中，对于图像的旋转、平移、缩放等操作，神经网络的输出应该是不变的。在神经网络中，可以通过数据增强的方法来进行处理。对于等变性，可以通过卷积神经网络来进行处理。CNN在设计的过程中，引入池化层<em>pooling</em>希望获得不变性。但是并没有获得很好的效果。</p>
<ul>
<li><strong>Invariance</strong>：对于输入的变化，输出不变<br>$$<br>f(T(X)) &#x3D; f(x)<br>$$</li>
<li><strong>Equivariance</strong>：对于输入的变化，输出也会发生相应的变化<br>$$<br>f(T(X)) &#x3D; T(f(x))<br>$$<br>在实践中，有时候会有噪声、形变、翻转、光照条件、视角变化、遮挡、尺度变化、类内类间差距、奇异等问题。</li>
</ul>
<h4 id="Data-Augmentation"><a href="#Data-Augmentation" class="headerlink" title="Data Augmentation"></a>Data Augmentation</h4><p>在实践中，可以通过数据增强的方法来进行处理。对于图像的旋转、平移、缩放、翻转等操作，可以增加数据的多样性。在训练的过程中，可以使用不同的数据增强的方法来进行训练。用这样的方法期望获得一种不变性。</p>
<p>常用的方法有：裁剪、旋转、翻转、缩放、平移、仿射变换、弹性变换、颜色变换等。<br>CNN识别主要使的是纹理的识别方法，希望将人类的对于形状识别的能力融入到CNN中。可以使用的数据集为<em>Augmentation by Stylization</em>，希望获得模型对于纹理的不变性。<br>CNN对上下文是敏感的，对于经常出现在一起的事物，CNN可以很好地进行识别，但是对于不常见的事物，CNN的效果会变差。一种极端的方式是将不经常出现的东西组合在一起。目前的深度网络一定程度上利用了<em>spurious correlation</em>，从而进行bench mark在数据集上过拟和。</p>
<h4 id="Architecture-Revolution"><a href="#Architecture-Revolution" class="headerlink" title="Architecture Revolution"></a>Architecture Revolution</h4><h5 id="MAGA-Making-convolutional-networks-shift-invariant-again"><a href="#MAGA-Making-convolutional-networks-shift-invariant-again" class="headerlink" title="MAGA Making convolutional networks shift-invariant again"></a>MAGA Making convolutional networks shift-invariant again</h5><p>在CNN中，在平移过程中，网络很难获得平移不变性。在采用模糊之后的<em>pooling</em>可以获得一定程度上的平移不变性。</p>
<h5 id="Capsule-Network"><a href="#Capsule-Network" class="headerlink" title="Capsule Network"></a>Capsule Network</h5><p>CNN的缺点还有：不能保持物体之间的相对关系。在分类任务中，一般情况下强调的是不变性，而在一些细粒度识别任务中，强调的是等变性。在Capsule Network中，引入了胶囊的概念，这样的操作可以保持物体之间的相对关系。</p>
<h2 id="CNN-Architectures"><a href="#CNN-Architectures" class="headerlink" title="CNN Architectures"></a>CNN Architectures</h2><h3 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h3><p><img src="D:/software/Git/images/%7B382F2347-B42F-46CB-83DB-F25DDE49A91E%7D.png" alt="{382F2347-B42F-46CB-83DB-F25DDE49A91E}.png"></p>
<ul>
<li>一般会在输入层使用较大的卷积核，然后在后面的层使用较小的卷积核</li>
<li>通道数随着网络逐渐增加然后减少</li>
<li>第一次使用ReLU激活函数</li>
<li>使用了大量的数据增强<em>Data Augmentation</em></li>
<li>使用GPU进行训练</li>
<li>采用SGD with momentum 0.9进行训练</li>
<li>使用dropout 0.5，一般在MLP层都需要使用dropout</li>
<li>使用0.01的学习率，然后在训练的过程中逐渐减小学习率，当loss不再下降的时使用学习率的0.1倍</li>
</ul>
<h4 id="ZFNet"><a href="#ZFNet" class="headerlink" title="ZFNet"></a>ZFNet</h4><p>在输入层使用了更小的卷积核，一般不要使用小的卷积核（更大的stride）会导致信息的丢失。<br>在中间层数使用了更多的通道数。</p>
<h3 id="VGGNet"><a href="#VGGNet" class="headerlink" title="VGGNet"></a>VGGNet</h3><p>用更小的卷积核来代替较大的卷积核，这样的操作可以减少参数量，增加网络的深度。在VGGNet中，使用了3个$3 \times 3$的卷积核来代替一个$7 \times 7$的卷积核。这样的操作可以增加网络的深度，减少参数量。<strong>一个较大的感受野可以通过多个较小的感受野来代替</strong>。但是现在又发现事实上没有这么好的效果，所以现在又开始使用较大的卷积核。</p>
<p>采用了预训练的方法。在训练的过程中，首先在较小的数据集上进行过拟和（在这个训练集上的损失函数接近0），然后在较大的数据集上进行训练。</p>
<p>在早期的网络中，池化层的使用是较多的，现在已经很少使用。</p>
<h3 id="NIN-Network-in-Network"><a href="#NIN-Network-in-Network" class="headerlink" title="NIN Network in Network"></a>NIN Network in Network</h3><p>在使用全连接层时，会有较多的参数，基于这样的思路提出$1\times 1$卷积这个操作。这样的操作只改变通道数，不改变空间尺寸，通常在不希望改变空间尺寸而增大通道数的时候可以使用。</p>
<p>在使用卷积增加步长、使用<em>pooling</em>层时候，会导致信息的丢失。在NIN中希望获得一个尺寸小但是通道数多的特征图。在NIN中使用了$1\times 1$的卷积核来增加通道数，这样可以使用空间全局池化。例如一个$256\times 6 \times 6$的特征图，使用$6\times 6$的全局池化，可以得到一个$256\times 1 \times 1$的特征图。</p>
<blockquote>
<p>[!NOTE]</p>
<ul>
<li>传统CNN末尾通常使用全连接层（FC）进行分类，但全连接层参数量大，易过拟合。</li>
<li>全局池化可直接将特征图转换为通道维度的向量（如$1\times 1 \times1024$ $\rightarrow$  1024维向量），再接一个分类层，大幅减少参数。</li>
</ul>
</blockquote>
<h4 id="GoogLeNet"><a href="#GoogLeNet" class="headerlink" title="GoogLeNet"></a>GoogLeNet</h4><p><img src="D:/software/Git/images/%7B43BF44F4-D211-4165-AE84-257E702582A0%7D.png" alt="{43BF44F4-D211-4165-AE84-257E702582A0}.png"><br>这是一个较为深的网络，删去了全连接层，参数量是较小的。</p>
<ul>
<li>引入Multi-passway，使用多路的卷积核来提取特征。采用了特征增广<em>Feature Augmentation</em>的方法。</li>
<li>在特征图通道数目不一样的情况下，使用padding的方法。</li>
</ul>
<p><img src="D:/software/Git/images/%7B6F8AFF72-4C3D-4FAD-8FC9-90F7FED6E8B2%7D.png" alt="{6F8AFF72-4C3D-4FAD-8FC9-90F7FED6E8B2}.png"></p>
<p><img src="D:/software/Git/images/%7B39D210C3-7C1B-4913-AC78-12E71A8FD13B%7D.png" alt="{39D210C3-7C1B-4913-AC78-12E71A8FD13B}.png"></p>
<p><img src="D:/software/Git/images/%7BE3B121C1-5782-4762-A983-042799DA4ED9%7D.png" alt="{E3B121C1-5782-4762-A983-042799DA4ED9}.png"></p>
<p>使用计算量越来越小的卷积核，使用计算量越来越小的卷积核，使用越来越多的层数，使用越来越多的通道数。</p>
<h4 id="Highway-Network"><a href="#Highway-Network" class="headerlink" title="Highway Network"></a>Highway Network</h4><p>在平坦的网络通路中，可能有信息通路瓶颈问题。在Highway Network中，引入了门控机制，这样的操作可以使得信息的流动更加顺畅。<br>$$<br>y&#x3D; H(x,W_H)T(x,W_T) + x(1-T(x,W_T))<br>$$<br>其中$H(x,W_H)$是一个MLP，$T(x,W_T)$是一个门控函数，这样的操作可以使得信息的流动更加顺畅。</p>
<ul>
<li><p>$x$: 输入向量。</p>
</li>
<li><p>$H(x, W_H)$: 非线性变换（如全连接层或卷积层）。</p>
</li>
<li><p>$T(x, W_T)$: Transform Gate（变换门），控制非线性变换的权重，通常用Sigmoid激活（输出值在0到1之间）。</p>
</li>
<li><p>$C(x, W_C)$: Carry Gate（携带门），控制原始输入 x 的权重。通常设定为 $C &#x3D; 1 - T$，以减少参数量。</p>
</li>
<li><p>当 $T(x)→0$ 时，输出$y≈x$，即当前层几乎不进行变换（信息直接跳过该层）。</p>
</li>
<li><p>当 $T(x)→1$ 时，输出$y≈H(x)$，即信息完全经过当前层的非线性变换。</p>
</li>
<li><p>通过这种方式，网络可以自适应地选择浅层或深层的特征。</p>
</li>
</ul>
<p>$$<br>T(x,W_T) &#x3D; \sigma(W_T^T x + b_T)<br>$$<br>动机是在网络中<strong>提高信息的流动性</strong></p>
<ul>
<li><strong>ResNet</strong>：使用恒等跳跃连接<em>Identity Skip Connection</em>，公式为 $y&#x3D;H(x)+x$，无门控机制。</li>
<li><strong>Highway Network</strong>：通过门控动态调节跳跃连接的权重，更灵活地控制信息流。</li>
</ul>
<h4 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h4><p><img src="D:/software/Git/images/%7B6767A6D4-59B6-4B62-9FE9-427D009BB837%7D.png" alt="{6767A6D4-59B6-4B62-9FE9-427D009BB837}.png"></p>
<ul>
<li>56层的模型比20层的模型效果更差，既然如此，先将20层的模型训练好，然后再增加36层的<em>identity</em>网络，之后再训练整个网络。发现这样的操作的效果反而更差。得出的结论是56层的网络更加难以训练，网络的拟和能力不足。<strong>平坦的网络很难拟和</strong></li>
<li>残差是更加容易拟和的。</li>
<li>继续将这些残差网络堆叠在一起，可以得到一个更深的网络。</li>
<li>卷积、池化是算子<em>operator</em>，残差是一个块<em>block</em>，网络是一个层<em>layer</em></li>
</ul>
<p><img src="D:/software/Git/images/%7B8F67BE27-E8CA-4921-99B2-C57FFFAE5E7B%7D.png" alt="{8F67BE27-E8CA-4921-99B2-C57FFFAE5E7B}.png"></p>
<p><img src="D:/software/Git/images/%7B681C5361-F2ED-427F-86C2-48C9EC68AADF%7D.png" alt="{681C5361-F2ED-427F-86C2-48C9EC68AADF}.png"></p>
<p><img src="D:/software/Git/images/%7B5DE8620F-D5FB-4E82-96D7-0E03CCCCAF82%7D.png" alt="{5DE8620F-D5FB-4E82-96D7-0E03CCCCAF82}.png"><br>对于网络会有多个维度进行评价：</p>
<ul>
<li>准确率top-1、top-5准确率</li>
<li>VGG网络参数量很大，但是由于是平坦的网络，所以有一定的计算整齐度。在网络有较多的分叉时，计算整齐度会变差。较为整齐的网络计算是较快的。</li>
<li>目前的显卡对于$3 \times 3$的卷积核是有硬件加速的</li>
</ul>
<h3 id="LandScape-Visualization"><a href="#LandScape-Visualization" class="headerlink" title="LandScape Visualization"></a>LandScape Visualization</h3><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1712.09913">[1712.09913] Visualizing the Loss Landscape of Neural Nets</a></p>
<h2 id="Lightweight-for-Deployment"><a href="#Lightweight-for-Deployment" class="headerlink" title="Lightweight for Deployment"></a>Lightweight for Deployment</h2><h3 id="Pruning"><a href="#Pruning" class="headerlink" title="Pruning"></a>Pruning</h3><p>卷积神经网络是一个很适合做剪枝的网络。说明神经网络的有很多的参数是冗余的。剪枝配合上重训练可以减少网络的参数量，并且在一定的程度上提升网络的性能。</p>
<h4 id="Quantization-and-Encoding"><a href="#Quantization-and-Encoding" class="headerlink" title="Quantization and Encoding"></a>Quantization and Encoding</h4><p>k-means算法可以将权重量化，将权重量化为几个值，这样的操作可以减少网络的参数量。在实际的操作中，可以将权重量化为8位，这样的操作可以减少网络的参数量。</p>
<p>编码操作，如Huffman编码，可以减少网络的参数量。<br><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1510.00149">[1510.00149] Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding</a></p>
<p>神经网络一般是在训练的时候使用较大的网络，然后再裁剪为较小的网络，反之效果不一定会好。</p>
<p>我们相信在裁剪的过程中，保留下来的参数是重要的参数，这样的操作可以提升网络的性能。在实验中</p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1803.03635">[1803.03635] The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks</a></p>
<p>先设计一个较小的网络，之后推广到较大的网络。在实际的操作中，可以使用较小的网络，然后再增加网络的深度。这种设计是硬件友好的，由于这样的设计是计算对齐的。</p>
<h4 id="Group-Convolution"><a href="#Group-Convolution" class="headerlink" title="Group Convolution"></a>Group Convolution</h4><p>标准的卷积层有这样的不足：对于不同的输入通道，后面的输出都使用到了所有的输入通道。在Group Convolution中，将输入通道分为几个组，然后对于每一个组使用一个卷积核。这样的操作可以减少网络的参数量，减少计算量。</p>
<p>但是通道之间不交流，这样的操作可能会导致网络的性能下降。</p>
<h4 id="Depthwise-Separable-Convolution"><a href="#Depthwise-Separable-Convolution" class="headerlink" title="Depthwise Separable Convolution"></a>Depthwise Separable Convolution</h4><ul>
<li>引入了$1 \times 1$卷积核<em>pointwise</em>，这样的操作可以减少参数量</li>
<li>令通道数等于分组数目<em>channelwise</em> or <em>depthwise</em></li>
</ul>
<p>上述两个算子是轻量化网络的基础。</p>
<p><img src="D:/software/Git/images/Pasted%20image%2020250316132626.png" alt="Pasted image 20250316132626.png"></p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2201.03545">[2201.03545] A ConvNet for the 2020s</a></p>
<p><img src="D:/software/Git/images/Pasted%20image%2020250316134751.png" alt="Pasted image 20250316134751.png"></p>
<p>宏观设计：<strong>减少空间尺寸的衰减有利于学习不同的特征</strong>。</p>
<h2 id="Advanced-Modules"><a href="#Advanced-Modules" class="headerlink" title="Advanced Modules"></a>Advanced Modules</h2><h3 id="3D-Modeling"><a href="#3D-Modeling" class="headerlink" title="3D Modeling"></a>3D Modeling</h3><p>普通的二维卷积网络在处理视频时，会丢失时间信息。在3D卷积网络中，引入了时间维度，这样的操作可以保留时间信息。</p>
<p>直接使用3D卷积可以进行直接的对应。</p>
<h4 id="Deforamble-Convolution"><a href="#Deforamble-Convolution" class="headerlink" title="Deforamble Convolution"></a>Deforamble Convolution</h4><p>在CNN中，形变较难进行建模，对于形变的物体效果会变差。在识别的过程中，在识别的过程中可能引入噪音。在Spatial Transformer Network中，引入了形变的概念，类似于视觉中进行防抖的操作。</p>
<p>在CNN中引入偏置的概念，在对应的特征图上进行坐标的偏置操作<br>$$<br>y(p_0) &#x3D; \sum_{p_i \in \Omega} w_i x(p_i+p_0+\Delta p_0)<br>$$</p>
<h4 id="Attention"><a href="#Attention" class="headerlink" title="Attention"></a>Attention</h4><p>要建模大范围的特征范围，就是high-level的特征，但是在使用CNN的过程中，有效感受野并没有那么大。</p>
<p>$$<br>y_i &#x3D; \frac{1}{\mathcal{C}(x)}\sum_{\forall j} f(x_i,x_j)g(x_j)<br>$$<br>对于注意力函数$f(x_i,x_j)$可以计算为两个参数的内积。上述操作实际上是一种全局建模，可以在CNN的最后几步使用。</p>
<h4 id="CAM"><a href="#CAM" class="headerlink" title="CAM"></a>CAM</h4><p>作为一种可解释性的工作，CAM可以将CNN的输出映射到输入图像上，这样的操作可以直观地看到CNN的输出。计算不同部分的权重，可以得到不同部分的重要性。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/06/21/Deep%20Learning%20Lecture-3/" data-id="cmca6f7u20003xkvaae0z79ot" data-title="Deep Learning Lecture-3" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/DeepLearning/" rel="tag">DeepLearning</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2025/06/21/Deep%20Learning%20Lecture-1/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Deep Learning Lecture-1
        
      </div>
    </a>
  
  
    <a href="/2025/06/21/Deep%20Learning%20Lecture-4/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Deep Learning Lecture-4</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/DeepLearning/" rel="tag">DeepLearning</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/DeepLearning/" style="font-size: 10px;">DeepLearning</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/06/">June 2025</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2025/06/21/Deep%20Learning%20Lecture-2/">Deep Learning Lecture-2</a>
          </li>
        
          <li>
            <a href="/2025/06/21/Deep%20Learning%20Lecture-1/">Deep Learning Lecture-1</a>
          </li>
        
          <li>
            <a href="/2025/06/21/Deep%20Learning%20Lecture-3/">Deep Learning Lecture-3</a>
          </li>
        
          <li>
            <a href="/2025/06/21/Deep%20Learning%20Lecture-4/">Deep Learning Lecture-4</a>
          </li>
        
          <li>
            <a href="/2025/06/21/Deep%20Learning%20Lecture-6/">Deep Learning Lecture-6</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2025 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>