<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Deep Learning Lecture-7 | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="Generative Model数据分布是生成模型的核心。生成模型的目标是学习数据的分布，然后生成新的数据。目标是学习数据的分布，然后生成新的数据。对生成模型的评价是通过生成的数据的质量来评价的，生成的数据越接近真实数据，生成模型的质量越好。$$\theta^* &#x3D; \arg\max_{\theta} \mathbb{E}_{x \sim p_{data}} \log p_{model">
<meta property="og:type" content="article">
<meta property="og:title" content="Deep Learning Lecture-7">
<meta property="og:url" content="http://example.com/2025/06/21/Deep%20Learning%20Lecture-7/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="Generative Model数据分布是生成模型的核心。生成模型的目标是学习数据的分布，然后生成新的数据。目标是学习数据的分布，然后生成新的数据。对生成模型的评价是通过生成的数据的质量来评价的，生成的数据越接近真实数据，生成模型的质量越好。$$\theta^* &#x3D; \arg\max_{\theta} \mathbb{E}_{x \sim p_{data}} \log p_{model">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="d:/software/Git/images/Pasted%20image%2020250330094251.png">
<meta property="og:image" content="d:/software/Git/images/Pasted%20image%2020250330094404.png">
<meta property="og:image" content="d:/software/Git/images/Pasted%20image%2020250330100434.png">
<meta property="og:image" content="d:/software/Git/images/Pasted%20image%2020250330100506.png">
<meta property="og:image" content="d:/software/Git/images/Pasted%20image%2020250330102359.png">
<meta property="og:image" content="d:/software/Git/images/Pasted%20image%2020250330141642.png">
<meta property="og:image" content="d:/software/Git/images/Pasted%20image%2020250330142308.png">
<meta property="og:image" content="d:/software/Git/images/Pasted%20image%2020250330144259.png">
<meta property="og:image" content="d:/software/Git/images/Pasted%20image%2020250330144556.png">
<meta property="og:image" content="d:/software/Git/images/Pasted%20image%2020250330153629.png">
<meta property="og:image" content="d:/software/Git/images/Pasted%20image%2020250330161028.png">
<meta property="og:image" content="d:/software/Git/images/Pasted%20image%2020250330164549.png">
<meta property="og:image" content="d:/software/Git/images/Pasted%20image%2020250403144444.png">
<meta property="og:image" content="d:/software/Git/images/Pasted%20image%2020250403152841.png">
<meta property="og:image" content="d:/software/Git/images/Pasted%20image%2020250403164408.png">
<meta property="og:image" content="d:/software/Git/images/Pasted%20image%2020250403165731.png">
<meta property="og:image" content="d:/software/Git/images/Pasted%20image%2020250405094553.png">
<meta property="og:image" content="d:/software/Git/images/Pasted%20image%2020250405161801.png">
<meta property="og:image" content="d:/software/Git/images/Pasted%20image%2020250405163042.png">
<meta property="og:image" content="d:/software/Git/images/Pasted%20image%2020250405163350.png">
<meta property="og:image" content="d:/software/Git/images/Pasted%20image%2020250405163425.png">
<meta property="og:image" content="d:/software/Git/images/Pasted%20image%2020250405163914.png">
<meta property="og:image" content="d:/software/Git/images/Pasted%20image%2020250405163941.png">
<meta property="og:image" content="d:/software/Git/images/Pasted%20image%2020250405164110.png">
<meta property="article:published_time" content="2025-06-20T16:00:00.000Z">
<meta property="article:modified_time" content="2025-06-23T14:55:17.302Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="DeepLearning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="d:/software/Git/images/Pasted%20image%2020250330094251.png">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/fork-awesome@1.2.0/css/fork-awesome.min.css">





<script>
  MathJax = {
    tex: {
      // vvvvv  请务必确认存在这一行 vvvvv
      packages: {'[+]': ['ams']},
      // ^^^^^  请务必确认存在这一行 ^^^^^
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$', '$$'], ['\\[', '\\]']],
      processEscapes: true,
      processEnvironments: true
    },
    options: {
      skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
    }
  };
</script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<meta name="generator" content="Hexo 7.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-Deep Learning Lecture-7" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/06/21/Deep%20Learning%20Lecture-7/" class="article-date">
  <time class="dt-published" datetime="2025-06-20T16:00:00.000Z" itemprop="datePublished">2025-06-21</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      Deep Learning Lecture-7
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <hr>
<h2 id="Generative-Model"><a href="#Generative-Model" class="headerlink" title="Generative Model"></a>Generative Model</h2><p>数据分布是生成模型的核心。生成模型的目标是学习数据的分布，然后生成新的数据。目标是<strong>学习数据的分布</strong>，然后生成新的数据。<br>对生成模型的评价是通过生成的数据的质量来评价的，生成的数据越接近真实数据，生成模型的质量越好。<br>$$<br>\theta^* &#x3D; \arg\max_{\theta} \mathbb{E}_{x \sim p_{data}} \log p_{model}(x|\theta)<br>$$<br><img src="D:/software/Git/images/Pasted%20image%2020250330094251.png" alt="Pasted image 20250330094251.png"></p>
<p><img src="D:/software/Git/images/Pasted%20image%2020250330094404.png" alt="Pasted image 20250330094404.png"></p>
<h3 id="GAN-Generative-Adversarial-Network"><a href="#GAN-Generative-Adversarial-Network" class="headerlink" title="GAN: Generative Adversarial Network"></a>GAN: Generative Adversarial Network</h3><p>对抗机器学习的思想是通过两个网络之间的对抗来学习。生成器和判别器之间的对抗是GAN的核心思想。<br>使用的博弈问题的思想，使用的是最小化最大的思想。</p>
<p>GAN的思想为：生成器和判别器之间的对抗，生成器生成数据，判别器判断数据的真实性。</p>
<p>目标函数为：<br>$$<br>\min_G \max_D V(D,G) &#x3D; \mathbb{E}_{x \sim p_{data}(x)}[\log D(x)] + \mathbb{E}_{z \sim p_z(z)}[\log(1-D(G(z)))]<br>$$</p>
<ul>
<li>当生成器固定时，判别器的目标是最大化判别器的准确率：$\max_D V(D,G)$</li>
<li>当判别器固定时，生成器的目标是最小化判别器的准确率：$\min_G V(D,G)$</li>
</ul>
<p>生成器 $G$ 的实质是将噪声分布 $p_z(z)$（如高斯分布）映射到数据分布 $p_g(x)$。根据概率密度变换定理，若 $G$ 是可逆且光滑的函数，则生成数据的分布为：</p>
<p>$$<br>p_g(x) &#x3D; p_z(z) \cdot \left| \det \left( \frac{\partial G^{-1}(x)}{\partial x} \right) \right|<br>$$</p>
<p>尽管深度神经网络通常不可逆，但通过足够复杂的函数逼近（如多层非线性变换），生成器可以隐式地学习到从 $p_z(z)$ 到 $p_g(x)$ 的映射，覆盖真实分布 $p_{data}(x)$。</p>
<p><strong>关键点</strong>：  </p>
<ul>
<li>噪声输入的随机性确保了生成数据分布的多样性。  </li>
<li>网络的非线性能力允许从简单分布（如高斯分布）逼近复杂分布（如图像像素分布）。</li>
</ul>
<p>但是GAN的<strong>训练过程是非常困难</strong>的，梯度性质是不好的，因为在比较好的样本中，由于梯度性质的问题会进行较大的更新。</p>
<p><img src="D:/software/Git/images/Pasted%20image%2020250330100434.png" alt="Pasted image 20250330100434.png"></p>
<p><strong>训练GAN的技巧</strong><br><img src="D:/software/Git/images/Pasted%20image%2020250330100506.png" alt="Pasted image 20250330100506.png"></p>
<h4 id="DCGAN-Deep-Convolutional-Generative-Adversarial-Networks"><a href="#DCGAN-Deep-Convolutional-Generative-Adversarial-Networks" class="headerlink" title="DCGAN: Deep Convolutional Generative Adversarial Networks"></a>DCGAN: Deep Convolutional Generative Adversarial Networks</h4><p>对于生成器和判别器，使用卷积神经网络来进行训练。对于判别器，使用的是较为标准的CNN网络，对于生成器，使用的是转置卷积，先将特征图进行padding，然后进行卷积操作，这样可以获得一个较大的特征图。</p>
<ul>
<li><strong>生成器</strong>：使用转置卷积（反卷积）逐步上采样，生成高分辨率图像。</li>
<li><strong>判别器</strong>：使用标准CNN逐步下采样。</li>
<li><strong>关键技巧</strong>：批量归一化、Leaky ReLU、全卷积结构。</li>
</ul>
<p><img src="D:/software/Git/images/Pasted%20image%2020250330102359.png" alt="Pasted image 20250330102359.png"></p>
<p>证明了泛化定理：在有限的训练样本之下，可以通过训练得到一个泛化的模型。</p>
<h4 id="Inception-Score"><a href="#Inception-Score" class="headerlink" title="Inception Score"></a>Inception Score</h4><p>IS 用于衡量生成模型的性能，重点关注两点：  </p>
<ul>
<li><strong>类别明确性</strong>：单个生成样本应明确属于某个类别（对应分类概率尖锐）。  </li>
<li><strong>多样性</strong>：生成样本应覆盖多个类别（类别分布均匀）。</li>
</ul>
<p>$$<br>\text{IS} &#x3D; \exp\left(\mathbb{E}_{x \sim p_g} \left[ \text{KL}\left(p(y|x) \parallel p(y)\right) \right]\right)<br>$$</p>
<ul>
<li>Class Probability Distribution: $p(y|x)$，生成样本 $x$ 属于各个类别的概率，度量的是生成的数据的类别分布和真实数据的类别分布的相似性。</li>
<li>Marginal Distribution of Generated Data: $p(y)$，度量的是生成的数据的类别分布的多样性，如果生成的数据是单一的称为模式坍塌。</li>
</ul>
<h5 id="KL-Divergence"><a href="#KL-Divergence" class="headerlink" title="KL Divergence"></a>KL Divergence</h5><p>使用KL散度来度量两个分布的相似性：<br>$$<br>KL(p||q) &#x3D;\mathbb{E}_X \left(  \log \frac{p(x)}{q(x)} \right)&#x3D;\sum_{x \in \mathcal{X}} p(x) \log \frac{p(x)}{q(x)}<br>$$<br>需要上面的值尽可能偏大</p>
<ul>
<li><strong>KL散度的意义</strong>：  <ul>
<li><strong>$p(y|x)$ 尖锐</strong> → 分类概率集中（如某类概率接近 1），此时 $\text{KL}(p(y|x) \parallel p(y))$ 值大。  </li>
<li><strong>$p(y)$ 均匀</strong> → 生成样本覆盖所有类别，$\text{KL}$ 值的期望更大。</li>
</ul>
</li>
<li><strong>取指数的作用</strong>：将对数空间的值转换为正数，放大差异便于比较。</li>
</ul>
<h4 id="FID-Frechet-Inception-Distance"><a href="#FID-Frechet-Inception-Distance" class="headerlink" title="FID: Frechet Inception Distance"></a>FID: Frechet Inception Distance</h4><p>将生成的数据输入一个网络来提取特征，用得到的特征来拟和两个高斯分布，然后计算两个高斯分布的<em>Frechet Inception Distance</em>。这是有显式表达式的。</p>
<p>$$<br>\text{FID} &#x3D; \|\mu_r - \mu_g\|^2 + \text{Tr}\left(\Sigma_r + \Sigma_g - 2(\Sigma_r \Sigma_g)^{1&#x2F;2}\right)<br>$$</p>
<ul>
<li><strong>$\mu_r, \mu_g$</strong>：真实数据和生成数据特征的均值向量。  </li>
<li><strong>$\Sigma_r, \Sigma_g$</strong>：真实数据和生成数据特征的协方差矩阵。  </li>
<li><strong>$\text{Tr}(\cdot)$</strong>：矩阵的迹（对角线元素之和）。</li>
</ul>
<h4 id="Mode-Collapse"><a href="#Mode-Collapse" class="headerlink" title="Mode Collapse"></a>Mode Collapse</h4><p>指生成的数据的多样性不够，类别分布是单一的，这是GAN的一个问题。</p>
<p>原始GAN使用JS散度（$JSD(p_{data} \parallel p_g)$）衡量分布距离，存在：</p>
<ul>
<li><strong>梯度消失</strong>：当 $p_g$ 和 $p_{data}$ 无重叠时，$JSD &#x3D; \log 2$，梯度为零。</li>
<li><strong>模式坍塌</strong>：生成器倾向于生成少数样本。</li>
</ul>
<h5 id="Wasserstein-Distance"><a href="#Wasserstein-Distance" class="headerlink" title="Wasserstein Distance"></a>Wasserstein Distance</h5><p><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%B2%83%E7%91%9F%E6%96%AF%E5%9D%A6%E5%BA%A6%E9%87%8F">沃瑟斯坦度量 - 维基百科，自由的百科全书</a></p>
<p>有可能统计距离是不是一个好的距离度量。Wasserstein距离是一个好的距离度量，用推土机距离来度量两个分布的距离。</p>
<p>$$ c(x,y) \mapsto [0, \infty), $$<br>表示从点$x$运输质量到点$y$的代价。一个从$\mu$到$\nu$的运输方案可以用函数$\gamma(x,y)$来描述，该函数表明从$x$移动到$y$的质量。一个运输方案$\gamma(x,y)$必须满足以下性质：<br>$$<br>\begin{aligned}<br>\int \gamma(x,y) \, \mathrm{d}y &#x3D; \mu(x), \\<br>\int \gamma(x,y) \, \mathrm{d}x &#x3D; \nu(y),<br>\end{aligned}<br>$$</p>
<p>前者表示从某一点$x$移到其他所有点的土堆总质量必须等于最初该点$x$上的土堆质量，后者则表示从所有点移到某一点$y$的土堆总质量必须等于最终该点$y$上的土堆质量。<br>$$<br>\iint c(x,y) \gamma(x,y) \, \mathrm{d}x \, \mathrm{d}y &#x3D; \int c(x,y) \, \mathrm{d}\gamma(x,y).<br>$$</p>
<p>方案$\gamma$并不是唯一的，所有可能的运输方案中代价最低的方案即为最优运输方案。最优运输方案的代价为：</p>
<p>$$<br>C &#x3D; \inf_{\gamma \in \Gamma(\mu,\nu)} \int c(x,y) \, \mathrm{d}\gamma(x,y).<br>$$</p>
<h5 id="Wasserstein-GAN"><a href="#Wasserstein-GAN" class="headerlink" title="Wasserstein GAN"></a>Wasserstein GAN</h5><p><img src="D:/software/Git/images/Pasted%20image%2020250330141642.png" alt="Pasted image 20250330141642.png"></p>
<p><img src="D:/software/Git/images/Pasted%20image%2020250330142308.png" alt="Pasted image 20250330142308.png"></p>
<p>对于模式坍塌进一步的理解，如果空间上有一个较大的利普希茨系数，那么说明发生了模式坍塌。</p>
<p><img src="D:/software/Git/images/Pasted%20image%2020250330144259.png" alt="Pasted image 20250330144259.png"></p>
<h5 id="Spectral-Normalization"><a href="#Spectral-Normalization" class="headerlink" title="Spectral Normalization"></a>Spectral Normalization</h5><p><img src="D:/software/Git/images/Pasted%20image%2020250330144556.png" alt="Pasted image 20250330144556.png"></p>
<table>
<thead>
<tr>
<th>指标</th>
<th>JS散度</th>
<th>Wasserstein距离</th>
</tr>
</thead>
<tbody><tr>
<td><strong>连续性</strong></td>
<td>不连续（梯度消失）</td>
<td>连续</td>
</tr>
<tr>
<td><strong>对称性</strong></td>
<td>对称</td>
<td>对称</td>
</tr>
<tr>
<td><strong>计算复杂度</strong></td>
<td>低</td>
<td>高（需约束判别器）</td>
</tr>
</tbody></table>
<h4 id="Conditional-GAN"><a href="#Conditional-GAN" class="headerlink" title="Conditional GAN"></a>Conditional GAN</h4><p>给定一个类来进行生成数据，这样可以生成不同类别的数据，这样可以生成更加多样的数据。并且可以在一定程度上避免模式坍塌。<br>除了接受高斯噪声还接受一个标签&#x2F;图像等等作为输入。</p>
<h4 id="ACGAN-Auxiliary-Classifier-GAN"><a href="#ACGAN-Auxiliary-Classifier-GAN" class="headerlink" title="ACGAN: Auxiliary Classifier GAN"></a>ACGAN: Auxiliary Classifier GAN</h4><p>是多任务学习的一种方法，除了生成数据，还可以进行分类。在生成数据的过程中还生成标签，所以可以一定程度上避免模式坍塌。</p>
<h4 id="Cycle-GAN"><a href="#Cycle-GAN" class="headerlink" title="Cycle GAN"></a>Cycle GAN</h4><p><img src="D:/software/Git/images/Pasted%20image%2020250330153629.png" alt="Pasted image 20250330153629.png"></p>
<p>无配对数据下的图像转换（如马→斑马），通过循环一致性损失$Cyc$保证生成的图像在两个方向上的转换是一致的。</p>
<h3 id="Self-Attention-GAN"><a href="#Self-Attention-GAN" class="headerlink" title="Self-Attention GAN"></a>Self-Attention GAN</h3><p>将<em>Self-Attention</em>机制应用到GAN中，这样可以使得生成的数据更加真实。</p>
<h4 id="Adaptive-Instance-Normalization"><a href="#Adaptive-Instance-Normalization" class="headerlink" title="Adaptive Instance Normalization"></a>Adaptive Instance Normalization</h4><p>$$<br>AdaIN(u ,v) &#x3D; \sigma(v) \left(\frac{u - \mu(u)}{\sigma(u)}\right) + \mu(v)<br>$$<br>本质上为重新着色的操作，将一个图像的风格转移到另一个图像上。</p>
<h4 id="StyleGAN"><a href="#StyleGAN" class="headerlink" title="StyleGAN"></a>StyleGAN</h4><p>通过控制风格来生成数据，这样可以生成更加多样的数据。</p>
<h3 id="VAE"><a href="#VAE" class="headerlink" title="VAE"></a>VAE</h3><h4 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h4><ol>
<li><strong>推断潜在变量分布</strong><br> 编码器将输入数据（如图像、文本）映射到潜在空间<em>latent space</em>，输出潜在变量$z$的概率分布参数（通常是高斯分布的均值和方差）。这一步称为<strong>变分推断</strong>，目的是找到输入数据在低维潜在空间中的概率表示。</li>
<li><strong>数据压缩与特征提取</strong><br> 编码器将高维输入数据压缩到低维潜在变量$z$，提取数据的关键特征（如形状、颜色等抽象属性），同时去除冗余信息。</li>
<li><strong>引入不确定性</strong><br> 不同于传统自编码器的确定性编码，VAE的编码器输出的是分布的参数，通过随机采样生成 zz，使得潜在空间具有连续性，便于生成新样本。</li>
</ol>
<h4 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h4><ol>
<li><strong>数据生成</strong><br> 解码器从潜在变量$z$出发，重构输入数据$x$的分布（如像素值的伯努利分布或高斯分布），生成与原始数据相似的新样本。</li>
<li><strong>潜在空间映射到数据空间</strong><br> 解码器学习如何将低维潜在变量$z$解码为高维数据空间中的样本，捕捉数据生成过程的规律（如像素间的依赖关系）。</li>
<li><strong>生成多样性</strong><br> 由于潜在变量$z$是连续且概率化的，解码器可以在潜在空间中插值或随机采样，生成多样化且合理的新数据。</li>
</ol>
<h4 id="Why-Variational"><a href="#Why-Variational" class="headerlink" title="Why Variational"></a>Why Variational</h4><p>其核心目标是通过学习数据分布$p(x)$，生成与训练数据类似的新样本。具体来说，VAE旨在解决以下问题：</p>
<ul>
<li><strong>生成新数据</strong>：例如生成图像、文本或音频。</li>
<li><strong>学习潜在表示</strong>：将高维数据映射到低维潜在空间，同时保持数据的语义特征。</li>
<li><strong>概率建模</strong>：显式定义数据的生成过程$p_{\theta} (x|z)$，并引入潜在变量$z$表示数据的隐含因素</li>
</ul>
<p>在VAE中，我们引入一个潜在变量 $z$，假设数据 $x$ 是由某个先验分布 $p_\theta(z)$ 生成，然后通过条件分布 $p_\theta(x|z)$ 生成可观测数据 $x$。<br>$$<br>p_\theta (x) &#x3D; \int p_\theta(x|z) p_\theta(z) \, \mathrm{d}z<br>$$<br>$z$的分布是一个高斯分布，对于$z$采样得到的实例，通过一个网络生成$x$。困难在于上面的反常积分，这是一个高维积分，不可行。可以使用<em>蒙特卡洛</em>。</p>
<p>对于后验分布：<br>$$<br>p_\theta(z|x) &#x3D; \frac{p_\theta(x|z) p_\theta(z)}{p_\theta(x)}<br>$$<br>在积分中是经常使用的，但是计算是NP-hard的，因此引入<strong>变分推断</strong>，通过优化下界（ELBO）间接逼近。直接求后验往往是不可行的。因此，我们用<strong>变分推断</strong>的方式，去学习一个近似后验分布$q_{\phi}(z∣x)$，并用它来逼近真正的后验分布$p_{\theta}(z∣x)$，从而得到一个变分下界。</p>
<p>变分的意思为变量的替换，在概率中为分布率的替换。<br>对于这个问题，可以使用一个神经网络来实现，对于这种显式的分布，需要假设分布率，可以指定为高斯分布，用网络来学习均值和协方差，作为<em>Encoder Network</em>。<br>对于条件分布$p_\theta(x|z)$，也可以假定为高斯分布，这样可以计算均值和协方差，作为<em>Decoder Network</em>。</p>
<p><img src="D:/software/Git/images/Pasted%20image%2020250330161028.png" alt="Pasted image 20250330161028.png"></p>
<p>但是VAE是<em>Intractable</em>的，这个问题是NP-hard的。对于上面的条件概率，是比较困难的。所以采用一个近似的方法来进行求解。比如假设服从一个高斯分布，之后计算这个分布的均值和协方差矩阵。</p>
<h4 id="ELBO-Evidence-Lower-Bound"><a href="#ELBO-Evidence-Lower-Bound" class="headerlink" title="ELBO: Evidence Lower Bound"></a>ELBO: Evidence Lower Bound</h4><p>训练的目的是使得$\log p_\theta (x_i)$尽可能大，但是很难计算，这里引入“参考系”，也就是引入一个近似的分布$q_\phi(z|x_i)$。</p>
<p><img src="D:/software/Git/images/Pasted%20image%2020250330164549.png" alt="Pasted image 20250330164549.png"></p>
<p>这里是将最大化似然的过程简化为最大化ELBO的过程。<br>$$<br>\log p_\theta (x_i) &#x3D; \mathbb{E}_{q_\phi(z|x_i)} \left[ \log p_\theta(x_i|z) \right] - KL (q_\phi(z|x_i) || p_\theta(z))<br>$$</p>
<h4 id="Reparameterization-Trick"><a href="#Reparameterization-Trick" class="headerlink" title="Reparameterization Trick"></a>Reparameterization Trick</h4><p><img src="D:/software/Git/images/Pasted%20image%2020250403144444.png" alt="Pasted image 20250403144444.png"></p>
<p>在VAE的训练过程中，通常需要从潜在变量的分布中采样。直接从分布中采样可能导致梯度无法传播到编码器网络，因此引入了重参数化技巧。<br>这是的采样变量是$\epsilon$，这样的话采样的过程就在计算图的旁路上，这样就可以进行梯度的传播。</p>
<h4 id="VAE-Inference"><a href="#VAE-Inference" class="headerlink" title="VAE Inference"></a>VAE Inference</h4><p>在训练的时候是从$x$中采样得到的，然后由后验分布$q_\phi(z|x)$来进行采样。而在推理过程中，是从潜在变量$z$中采样得到的，然后由条件分布$p_\theta(x|z)$来进行进行推理。<br>上述过程的合理性在于目标函数ELBO中的第二项：$KL (q_\phi(z|x_i) || p_\theta(z))$在训练中被最小化了。</p>
<p><img src="D:/software/Git/images/Pasted%20image%2020250403152841.png" alt="Pasted image 20250403152841.png"></p>
<h4 id="VQ-VAE"><a href="#VQ-VAE" class="headerlink" title="VQ-VAE"></a>VQ-VAE</h4><p>VQ-VAE是对VAE的一个改进，使用了向量量化的方法来进行训练。通过对潜在变量进行离散化来进行训练，这样可以避免模式坍塌的问题。</p>
<h3 id="Diffusion-Probabilistic-Models"><a href="#Diffusion-Probabilistic-Models" class="headerlink" title="Diffusion Probabilistic Models"></a>Diffusion Probabilistic Models</h3><h4 id="Denoising-Diffusion-Probabilistic-Models"><a href="#Denoising-Diffusion-Probabilistic-Models" class="headerlink" title="Denoising Diffusion Probabilistic Models"></a>Denoising Diffusion Probabilistic Models</h4><p>Diffusion模型是通过对数据进行逐步添加噪声来训练模型的。通过对数据进行逐步添加噪声，然后再通过一个网络来进行去噪声的操作。这样可以生成新的数据。</p>
<p>Markovian Process: 逐步添加噪声的过程，通常是一个高斯分布的过程。<br>$$<br>q(x_t | x_{t-1}) &#x3D; \mathcal{N}(x_t; \sqrt{1-\beta_t}  x_{t-1}, \beta_t I)<br>$$<br>联合分布：<br>$$<br>q(x_{1:T} | x_0) &#x3D; \prod_{t&#x3D;1}^{T} q(x_t | x_{t-1})<br>$$</p>
<p>重参数化表达：<br>$$<br>x_t &#x3D; \sqrt{1-\beta_t} x_{t-1} + \sqrt{\beta_t} \epsilon \quad \epsilon \sim \mathcal{N}(0, I)<br>$$</p>
<h5 id="Diffusion-Kernel"><a href="#Diffusion-Kernel" class="headerlink" title="Diffusion Kernel"></a>Diffusion Kernel</h5><p>$$<br>\begin{aligned}<br>x_t &amp; &#x3D; \sqrt{1-\beta_t} x_{t-1} + \sqrt{\beta_t} \epsilon \\<br>&amp;&#x3D; \sqrt{\alpha_t} x_{t-1} + \sqrt{1-\alpha_t} \epsilon \\<br>&amp;&#x3D; \sqrt{\alpha_t \alpha_{t-1}} x_{t-2} + \sqrt{1-\alpha_t} \epsilon + \sqrt{\alpha_t} \sqrt{1-\alpha_{t-1}} \epsilon&#39; \\<br>&amp; &#x3D; \sqrt{\alpha_t \alpha_{t-1}} x_{t-2} + \sqrt{1 -  \alpha_t \alpha_{t-1}} \epsilon \\<br>&amp; \dots \\<br>&amp; &#x3D; \sqrt{\overline{\alpha_t}} x_0 + \sqrt{1 - \overline{\alpha_t}} \epsilon<br>\end{aligned}<br>$$</p>
<ul>
<li>其中 $\overline{\alpha_t} &#x3D; \prod_{s&#x3D;1}^{t} \alpha_s$</li>
</ul>
<h5 id="Generation-by-Denoising"><a href="#Generation-by-Denoising" class="headerlink" title="Generation by Denoising"></a>Generation by Denoising</h5><ul>
<li>首先对于$x_T$进行采样，得到一个高斯分布的样本。</li>
<li>然后利用后验分布得到$x_{t-1}$，使用Bayes公式：<br>$x_{t-1} \sim q(x_{t-1}|x_t) \propto q(x_{t-1}) q(x_t |x_{t-1})$</li>
</ul>
<p>采用一个变分方法来实现：<br>$$<br>p_{\theta}(x_{t-1}|x_t) &#x3D; \mathcal{N} \left(x_{t-1}; \mu_{\theta}(x_t, t), \sigma_t^2 \mathbf{I} \right)<br>$$<br>$$<br>p_\theta(x_{0:T}) &#x3D; p_\theta (x_T)\prod_{t&#x3D;1}^{T} p_\theta(x_{t-1}|x_t)<br>$$</p>
<p>上述过程可以使用一个网络来实现对于均值和方差的输出。</p>
<p><img src="D:/software/Git/images/Pasted%20image%2020250403164408.png" alt="Pasted image 20250403164408.png"></p>
<p><img src="D:/software/Git/images/Pasted%20image%2020250403165731.png" alt="Pasted image 20250403165731.png"></p>
<p><a target="_blank" rel="noopener" href="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/">What are Diffusion Models? | Lil&#39;Log</a></p>
<p><img src="D:/software/Git/images/Pasted%20image%2020250405094553.png" alt="Pasted image 20250405094553.png"></p>
<h5 id="Diffusion-Parameters"><a href="#Diffusion-Parameters" class="headerlink" title="Diffusion Parameters"></a>Diffusion Parameters</h5><p><img src="D:/software/Git/images/Pasted%20image%2020250405161801.png" alt="Pasted image 20250405161801.png"></p>
<h5 id="Acceleration-Strategies"><a href="#Acceleration-Strategies" class="headerlink" title="Acceleration Strategies"></a>Acceleration Strategies</h5><h5 id="Re-design-forward-Sampling"><a href="#Re-design-forward-Sampling" class="headerlink" title="Re-design forward Sampling"></a>Re-design forward Sampling</h5><ul>
<li>Striding Sampling<ul>
<li>在每个时间步长中跳过多个时间步进行采样，从而减少采样次数。</li>
<li>问题在于在相邻的时间戳中反向传播的后验分布可以近似为高斯分布，但是在较大的步长下不一定是这样的。</li>
</ul>
</li>
<li>DDIM: Denoising Diffusion Implicit Models<ul>
<li>通过设计一个新的前向采样过程来加速采样。</li>
<li>通过引入一个新的参数$\alpha_t$来控制前向采样的过程。</li>
<li>通过设计一个新的后验分布来进行采样。</li>
<li>通过设计一个新的损失函数来进行训练。</li>
<li><img src="D:/software/Git/images/Pasted%20image%2020250405163042.png" alt="Pasted image 20250405163042.png"></li>
</ul>
</li>
<li>Denosing Diffusion Models<ul>
<li><img src="D:/software/Git/images/Pasted%20image%2020250405163350.png" alt="Pasted image 20250405163350.png"></li>
</ul>
</li>
<li>Latent Diffusion Models<ul>
<li><img src="D:/software/Git/images/Pasted%20image%2020250405163425.png" alt="Pasted image 20250405163425.png"></li>
</ul>
</li>
</ul>
<h5 id="Conditonal-Diffusion-Models"><a href="#Conditonal-Diffusion-Models" class="headerlink" title="Conditonal Diffusion Models"></a>Conditonal Diffusion Models</h5><p><img src="D:/software/Git/images/Pasted%20image%2020250405163914.png" alt="Pasted image 20250405163914.png"></p>
<p><img src="D:/software/Git/images/Pasted%20image%2020250405163941.png" alt="Pasted image 20250405163941.png"></p>
<p><img src="D:/software/Git/images/Pasted%20image%2020250405164110.png" alt="Pasted image 20250405164110.png"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/06/21/Deep%20Learning%20Lecture-7/" data-id="cmc97xozr00080wvaa5sn4xot" data-title="Deep Learning Lecture-7" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/DeepLearning/" rel="tag">DeepLearning</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2025/06/21/Deep%20Learning%20Lecture-5/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Deep Learning Lecture-5
        
      </div>
    </a>
  
  
    <a href="/2025/06/21/Deep%20Learning%20Lecture-8/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Deep Learning Lecture-8</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/DeepLearning/" rel="tag">DeepLearning</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/DeepLearning/" style="font-size: 10px;">DeepLearning</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/06/">June 2025</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2025/06/21/Deep%20Learning%20Lecture-2/">Deep Learning Lecture-2</a>
          </li>
        
          <li>
            <a href="/2025/06/21/Deep%20Learning%20Lecture-1/">Deep Learning Lecture-1</a>
          </li>
        
          <li>
            <a href="/2025/06/21/Deep%20Learning%20Lecture-4/">Deep Learning Lecture-4</a>
          </li>
        
          <li>
            <a href="/2025/06/21/Deep%20Learning%20Lecture-3/">Deep Learning Lecture-3</a>
          </li>
        
          <li>
            <a href="/2025/06/21/Deep%20Learning%20Lecture-5/">Deep Learning Lecture-5</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2025 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>